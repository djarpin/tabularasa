{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc873c9a",
   "metadata": {},
   "source": [
    "# Tabula Rasa\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook trains a mixed monotonic model, with sub-models to generate arbitrary quantile predictions and estimate epistemic uncertainty, using `TabulaRasaRegressor()`.\n",
    "\n",
    "It's designed to work with Pandas DataFrame's and takes advantage of class types and feature names to cut down on code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5353a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tabularasa.TabulaRasa import TabulaRasaRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc062f2d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Load example data\n",
    "\n",
    "If you haven't already, please generate the example dataset using the [example_data](example_data.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87937eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/simple_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530b9603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y     float32\n",
       "x1    float32\n",
       "x2    float32\n",
       "x3      int64\n",
       "x4    float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704b773",
   "metadata": {},
   "source": [
    "Let's convert `x3` to a `category` data type to generate embeddings for it (`TabulaRasaRegressor()` automatically handles this for all columns with `object` or `category` data types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8043b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x3'] = df['x3'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd8aa6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Initialize model\n",
    "\n",
    "When initializing the model, we typically pass 3 arguments:\n",
    "- `df`: A `pandas.DataFrame` containing the training data, or a sample of it.  No training happens on initialization, just categorizing features, setting up categorical feature mappings, and scalers for numeric features.  Therefore, if it is a sample of the full dataset, it should well represent your full dataset (in terms of having unique values for each categorical feature, and distributions for continuous features).\n",
    "- `targets`: A `list` of column names to use as regressand(s) which are in `df`.  All other 'number', 'category', or 'object' columns in `df` are assumed to be features and will be included in the models. \n",
    "- `monotonic_constraints`: A `dict` where keys are features (column names on `df`) to take on monotonic relationships with the `targets` and values are 1 or -1 to signify the direction of that relationship: increasing or decreasing (respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cccc3722",
   "metadata": {},
   "outputs": [],
   "source": [
    "trr = TabulaRasaRegressor(df,\n",
    "                          targets=['y'],\n",
    "                          monotonic_constraints={'x1': 1, 'x2': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5b6cf7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training expectation model ***\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1      \u001b[36m511.3724\u001b[0m        \u001b[32m1.2401\u001b[0m  1.6692\n",
      "      2        \u001b[36m2.2265\u001b[0m        2.4904  1.5025\n",
      "      3        \u001b[36m1.8191\u001b[0m        1.4249  1.5021\n",
      "      4        \u001b[36m1.2452\u001b[0m        \u001b[32m0.9940\u001b[0m  1.4847\n",
      "      5        \u001b[36m1.0025\u001b[0m        \u001b[32m0.9934\u001b[0m  1.4985\n",
      "      6        1.0071        1.0043  1.5175\n",
      "      7        \u001b[36m1.0012\u001b[0m        \u001b[32m0.9929\u001b[0m  1.5700\n",
      "      8        \u001b[36m0.9996\u001b[0m        1.0122  1.4878\n",
      "      9        1.0146        0.9947  1.5187\n",
      "     10        1.0077        1.0039  1.5119\n",
      "     11        1.0051        0.9939  1.5087\n",
      "     12        1.0035        0.9955  1.4988\n",
      "     13        1.0028        0.9946  1.4965\n",
      "     14        1.0021        1.0005  1.4991\n",
      "     15        1.0029        \u001b[32m0.9928\u001b[0m  1.4858\n",
      "     16        1.0033        0.9959  1.4932\n",
      "     17        1.0023        0.9995  1.4942\n",
      "     18        1.0053        0.9934  1.4833\n",
      "     19        1.0060        0.9945  1.5005\n",
      "     20        1.0061        0.9953  1.5094\n",
      "     21        1.0092        1.0179  1.5020\n",
      "     22        1.0048        0.9930  1.4963\n",
      "     23        \u001b[36m0.9992\u001b[0m        1.0152  1.5008\n",
      "     24        1.0094        1.0042  1.4944\n",
      "     25        1.0139        1.0350  1.4919\n",
      "\n",
      "*** Training epistemic uncertainty model ***\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m22320.4898\u001b[0m     \u001b[32m5854.4909\u001b[0m  0.0344\n",
      "      2     \u001b[36m5615.2816\u001b[0m     \u001b[32m3716.0982\u001b[0m  0.0499\n",
      "      3     \u001b[36m1985.1650\u001b[0m     \u001b[32m1140.0236\u001b[0m  0.0445\n",
      "      4      \u001b[36m913.3235\u001b[0m      \u001b[32m561.9066\u001b[0m  0.0458\n",
      "      5      \u001b[36m377.1084\u001b[0m      \u001b[32m168.7670\u001b[0m  0.0453\n",
      "      6      \u001b[36m161.5225\u001b[0m      \u001b[32m107.6678\u001b[0m  0.0484\n",
      "      7       \u001b[36m67.3595\u001b[0m       \u001b[32m50.5948\u001b[0m  0.0437\n",
      "      8       \u001b[36m42.7245\u001b[0m       \u001b[32m23.7139\u001b[0m  0.0478\n",
      "      9       \u001b[36m23.6192\u001b[0m       \u001b[32m21.1844\u001b[0m  0.0498\n",
      "     10       \u001b[36m17.8883\u001b[0m       \u001b[32m16.6382\u001b[0m  0.0453\n",
      "     11       \u001b[36m15.5442\u001b[0m       \u001b[32m14.0994\u001b[0m  0.0454\n",
      "     12       \u001b[36m13.8950\u001b[0m       \u001b[32m13.2048\u001b[0m  0.0484\n",
      "     13       \u001b[36m12.7993\u001b[0m       \u001b[32m12.3979\u001b[0m  0.0488\n",
      "     14       \u001b[36m12.1369\u001b[0m       \u001b[32m11.8014\u001b[0m  0.0485\n",
      "     15       \u001b[36m11.5726\u001b[0m       \u001b[32m11.2663\u001b[0m  0.0473\n",
      "     16       \u001b[36m11.1810\u001b[0m       \u001b[32m10.9145\u001b[0m  0.0496\n",
      "     17       \u001b[36m10.6749\u001b[0m       \u001b[32m10.4423\u001b[0m  0.0495\n",
      "     18       \u001b[36m10.2507\u001b[0m       \u001b[32m10.1550\u001b[0m  0.0505\n",
      "     19        \u001b[36m9.9341\u001b[0m        \u001b[32m9.7330\u001b[0m  0.0511\n",
      "     20        \u001b[36m9.5912\u001b[0m        \u001b[32m9.4259\u001b[0m  0.0515\n",
      "     21        \u001b[36m9.3000\u001b[0m        \u001b[32m9.1637\u001b[0m  0.0511\n",
      "     22        \u001b[36m9.2107\u001b[0m        \u001b[32m8.9917\u001b[0m  0.0518\n",
      "     23        \u001b[36m8.8421\u001b[0m        \u001b[32m8.6907\u001b[0m  0.0514\n",
      "     24        \u001b[36m8.6022\u001b[0m        \u001b[32m8.5118\u001b[0m  0.0517\n",
      "     25        \u001b[36m8.3632\u001b[0m        \u001b[32m8.3852\u001b[0m  0.0587\n",
      "     26        \u001b[36m8.2282\u001b[0m        \u001b[32m8.1347\u001b[0m  0.0503\n",
      "     27        \u001b[36m8.0767\u001b[0m        \u001b[32m7.9938\u001b[0m  0.0442\n",
      "     28        \u001b[36m7.8360\u001b[0m        \u001b[32m7.7943\u001b[0m  0.0520\n",
      "     29        \u001b[36m7.6498\u001b[0m        \u001b[32m7.5915\u001b[0m  0.0507\n",
      "     30        \u001b[36m7.5209\u001b[0m        \u001b[32m7.4815\u001b[0m  0.0448\n",
      "     31        \u001b[36m7.3170\u001b[0m        \u001b[32m7.2425\u001b[0m  0.0449\n",
      "     32        \u001b[36m7.1576\u001b[0m        \u001b[32m7.1726\u001b[0m  0.0523\n",
      "     33        \u001b[36m7.0517\u001b[0m        \u001b[32m7.0443\u001b[0m  0.0460\n",
      "     34        \u001b[36m6.9482\u001b[0m        \u001b[32m6.8770\u001b[0m  0.0514\n",
      "     35        \u001b[36m6.7865\u001b[0m        \u001b[32m6.7893\u001b[0m  0.0540\n",
      "     36        \u001b[36m6.6746\u001b[0m        \u001b[32m6.5853\u001b[0m  0.0511\n",
      "     37        \u001b[36m6.4672\u001b[0m        \u001b[32m6.4044\u001b[0m  0.0511\n",
      "     38        \u001b[36m6.2965\u001b[0m        \u001b[32m6.2689\u001b[0m  0.0497\n",
      "     39        \u001b[36m6.1673\u001b[0m        \u001b[32m6.1634\u001b[0m  0.0434\n",
      "     40        \u001b[36m6.1417\u001b[0m        \u001b[32m6.0342\u001b[0m  0.0435\n",
      "     41        \u001b[36m5.9265\u001b[0m        6.0463  0.0441\n",
      "     42        \u001b[36m5.9151\u001b[0m        \u001b[32m5.8190\u001b[0m  0.0432\n",
      "     43        \u001b[36m5.7223\u001b[0m        \u001b[32m5.6593\u001b[0m  0.0451\n",
      "     44        \u001b[36m5.5557\u001b[0m        \u001b[32m5.5048\u001b[0m  0.0446\n",
      "     45        \u001b[36m5.4253\u001b[0m        \u001b[32m5.4117\u001b[0m  0.0546\n",
      "     46        \u001b[36m5.3155\u001b[0m        5.4333  0.0484\n",
      "     47        \u001b[36m5.2752\u001b[0m        \u001b[32m5.2129\u001b[0m  0.0554\n",
      "     48        \u001b[36m5.1409\u001b[0m        \u001b[32m5.1090\u001b[0m  0.0474\n",
      "     49        \u001b[36m5.0251\u001b[0m        \u001b[32m4.9838\u001b[0m  0.0544\n",
      "     50        \u001b[36m4.9065\u001b[0m        \u001b[32m4.8980\u001b[0m  0.0528\n",
      "     51        \u001b[36m4.8154\u001b[0m        \u001b[32m4.8172\u001b[0m  0.0540\n",
      "     52        \u001b[36m4.7382\u001b[0m        \u001b[32m4.7484\u001b[0m  0.0545\n",
      "     53        \u001b[36m4.6342\u001b[0m        \u001b[32m4.6008\u001b[0m  0.0538\n",
      "     54        \u001b[36m4.5520\u001b[0m        \u001b[32m4.5450\u001b[0m  0.0542\n",
      "     55        \u001b[36m4.4858\u001b[0m        \u001b[32m4.4571\u001b[0m  0.0459\n",
      "     56        \u001b[36m4.3831\u001b[0m        \u001b[32m4.3756\u001b[0m  0.0447\n",
      "     57        \u001b[36m4.3058\u001b[0m        \u001b[32m4.2738\u001b[0m  0.0542\n",
      "     58        \u001b[36m4.2050\u001b[0m        \u001b[32m4.2004\u001b[0m  0.0544\n",
      "     59        \u001b[36m4.1547\u001b[0m        4.2701  0.0544\n",
      "     60        4.1851        \u001b[32m4.1209\u001b[0m  0.0537\n",
      "     61        \u001b[36m4.0265\u001b[0m        \u001b[32m3.9556\u001b[0m  0.0541\n",
      "     62        \u001b[36m3.8891\u001b[0m        \u001b[32m3.8924\u001b[0m  0.0550\n",
      "     63        \u001b[36m3.8147\u001b[0m        \u001b[32m3.7802\u001b[0m  0.0551\n",
      "     64        \u001b[36m3.7514\u001b[0m        \u001b[32m3.7723\u001b[0m  0.0552\n",
      "     65        \u001b[36m3.6762\u001b[0m        \u001b[32m3.7244\u001b[0m  0.0451\n",
      "     66        \u001b[36m3.6284\u001b[0m        \u001b[32m3.6020\u001b[0m  0.0502\n",
      "     67        \u001b[36m3.5472\u001b[0m        \u001b[32m3.5503\u001b[0m  0.0556\n",
      "     68        \u001b[36m3.4739\u001b[0m        3.5824  0.0557\n",
      "     69        \u001b[36m3.4614\u001b[0m        \u001b[32m3.4261\u001b[0m  0.0556\n",
      "     70        \u001b[36m3.3492\u001b[0m        \u001b[32m3.3190\u001b[0m  0.0521\n",
      "     71        \u001b[36m3.2668\u001b[0m        \u001b[32m3.2735\u001b[0m  0.0466\n",
      "     72        \u001b[36m3.2229\u001b[0m        3.2857  0.0467\n",
      "     73        \u001b[36m3.2119\u001b[0m        \u001b[32m3.1782\u001b[0m  0.0448\n",
      "     74        \u001b[36m3.1436\u001b[0m        \u001b[32m3.1577\u001b[0m  0.0456\n",
      "     75        \u001b[36m3.0983\u001b[0m        3.2194  0.0545\n",
      "     76        \u001b[36m3.0732\u001b[0m        \u001b[32m3.0108\u001b[0m  0.0498\n",
      "     77        \u001b[36m2.9732\u001b[0m        \u001b[32m2.9401\u001b[0m  0.0501\n",
      "     78        \u001b[36m2.9177\u001b[0m        \u001b[32m2.9013\u001b[0m  0.0566\n",
      "     79        \u001b[36m2.8398\u001b[0m        \u001b[32m2.8369\u001b[0m  0.0555\n",
      "     80        \u001b[36m2.7822\u001b[0m        \u001b[32m2.7773\u001b[0m  0.0455\n",
      "     81        \u001b[36m2.7276\u001b[0m        \u001b[32m2.7217\u001b[0m  0.0555\n",
      "     82        \u001b[36m2.6791\u001b[0m        \u001b[32m2.6729\u001b[0m  0.0458\n",
      "     83        \u001b[36m2.6129\u001b[0m        \u001b[32m2.6217\u001b[0m  0.0555\n",
      "     84        \u001b[36m2.5579\u001b[0m        \u001b[32m2.5654\u001b[0m  0.0554\n",
      "     85        \u001b[36m2.5123\u001b[0m        \u001b[32m2.5100\u001b[0m  0.0592\n",
      "     86        \u001b[36m2.4721\u001b[0m        \u001b[32m2.4776\u001b[0m  0.0458\n",
      "     87        \u001b[36m2.4568\u001b[0m        \u001b[32m2.4485\u001b[0m  0.0508\n",
      "     88        \u001b[36m2.4121\u001b[0m        \u001b[32m2.4028\u001b[0m  0.0559\n",
      "     89        \u001b[36m2.3624\u001b[0m        \u001b[32m2.3867\u001b[0m  0.0557\n",
      "     90        \u001b[36m2.3314\u001b[0m        \u001b[32m2.3279\u001b[0m  0.0563\n",
      "     91        \u001b[36m2.3049\u001b[0m        2.3434  0.0450\n",
      "     92        \u001b[36m2.2608\u001b[0m        \u001b[32m2.2312\u001b[0m  0.0513\n",
      "     93        \u001b[36m2.2496\u001b[0m        2.2792  0.0562\n",
      "     94        \u001b[36m2.2157\u001b[0m        \u001b[32m2.2046\u001b[0m  0.0564\n",
      "     95        \u001b[36m2.1647\u001b[0m        \u001b[32m2.1763\u001b[0m  0.0466\n",
      "     96        \u001b[36m2.1160\u001b[0m        \u001b[32m2.1042\u001b[0m  0.0570\n",
      "     97        \u001b[36m2.0704\u001b[0m        \u001b[32m2.0558\u001b[0m  0.0640\n",
      "     98        \u001b[36m2.0192\u001b[0m        \u001b[32m2.0517\u001b[0m  0.0768\n",
      "     99        \u001b[36m2.0036\u001b[0m        \u001b[32m1.9951\u001b[0m  0.0600\n",
      "    100        \u001b[36m1.9687\u001b[0m        \u001b[32m1.9566\u001b[0m  0.0579\n",
      "    101        \u001b[36m1.9356\u001b[0m        \u001b[32m1.9241\u001b[0m  0.0491\n",
      "    102        \u001b[36m1.8900\u001b[0m        \u001b[32m1.9012\u001b[0m  0.0507\n",
      "    103        \u001b[36m1.8570\u001b[0m        \u001b[32m1.8498\u001b[0m  0.0583\n",
      "    104        \u001b[36m1.8150\u001b[0m        \u001b[32m1.8211\u001b[0m  0.0577\n",
      "    105        \u001b[36m1.7992\u001b[0m        \u001b[32m1.8182\u001b[0m  0.0581\n",
      "    106        1.8232        \u001b[32m1.8122\u001b[0m  0.0459\n",
      "    107        \u001b[36m1.7744\u001b[0m        \u001b[32m1.7739\u001b[0m  0.0461\n",
      "    108        \u001b[36m1.7413\u001b[0m        \u001b[32m1.7410\u001b[0m  0.0570\n",
      "    109        \u001b[36m1.6922\u001b[0m        \u001b[32m1.7071\u001b[0m  0.0469\n",
      "    110        \u001b[36m1.6688\u001b[0m        \u001b[32m1.6754\u001b[0m  0.0580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    111        \u001b[36m1.6334\u001b[0m        \u001b[32m1.6326\u001b[0m  0.0386\n",
      "    112        \u001b[36m1.6254\u001b[0m        \u001b[32m1.6225\u001b[0m  0.0492\n",
      "    113        \u001b[36m1.6026\u001b[0m        \u001b[32m1.5834\u001b[0m  0.0469\n",
      "    114        \u001b[36m1.5619\u001b[0m        \u001b[32m1.5536\u001b[0m  0.0440\n",
      "    115        \u001b[36m1.5368\u001b[0m        \u001b[32m1.5460\u001b[0m  0.0458\n",
      "    116        \u001b[36m1.5225\u001b[0m        \u001b[32m1.5262\u001b[0m  0.0427\n",
      "    117        \u001b[36m1.4981\u001b[0m        \u001b[32m1.4897\u001b[0m  0.0445\n",
      "    118        \u001b[36m1.4536\u001b[0m        \u001b[32m1.4543\u001b[0m  0.0448\n",
      "    119        \u001b[36m1.4196\u001b[0m        1.4736  0.0514\n",
      "    120        1.4253        \u001b[32m1.4154\u001b[0m  0.0487\n",
      "    121        \u001b[36m1.3837\u001b[0m        \u001b[32m1.3886\u001b[0m  0.0471\n",
      "    122        \u001b[36m1.3614\u001b[0m        \u001b[32m1.3686\u001b[0m  0.0477\n",
      "    123        \u001b[36m1.3373\u001b[0m        \u001b[32m1.3503\u001b[0m  0.0446\n",
      "    124        \u001b[36m1.3351\u001b[0m        \u001b[32m1.3375\u001b[0m  0.0436\n",
      "    125        \u001b[36m1.3081\u001b[0m        \u001b[32m1.3062\u001b[0m  0.0483\n",
      "    126        \u001b[36m1.2778\u001b[0m        \u001b[32m1.2903\u001b[0m  0.0447\n",
      "    127        \u001b[36m1.2585\u001b[0m        \u001b[32m1.2702\u001b[0m  0.0473\n",
      "    128        \u001b[36m1.2377\u001b[0m        \u001b[32m1.2351\u001b[0m  0.0440\n",
      "    129        \u001b[36m1.2237\u001b[0m        1.2373  0.0483\n",
      "    130        \u001b[36m1.2112\u001b[0m        \u001b[32m1.2169\u001b[0m  0.0449\n",
      "    131        \u001b[36m1.1930\u001b[0m        \u001b[32m1.2035\u001b[0m  0.0486\n",
      "    132        \u001b[36m1.1772\u001b[0m        \u001b[32m1.1916\u001b[0m  0.0453\n",
      "    133        \u001b[36m1.1572\u001b[0m        \u001b[32m1.1497\u001b[0m  0.0499\n",
      "    134        \u001b[36m1.1310\u001b[0m        \u001b[32m1.1376\u001b[0m  0.0503\n",
      "    135        \u001b[36m1.1225\u001b[0m        \u001b[32m1.1219\u001b[0m  0.0504\n",
      "    136        \u001b[36m1.1021\u001b[0m        \u001b[32m1.1060\u001b[0m  0.0455\n",
      "    137        \u001b[36m1.1011\u001b[0m        1.2976  0.0525\n",
      "    138        2.1396        1.1169  0.0523\n",
      "    139        1.6450        1.2288  0.0460\n",
      "    140        1.3223        \u001b[32m1.0497\u001b[0m  0.0428\n",
      "    141        1.1705        1.1061  0.0485\n",
      "    142        1.1786        1.2284  0.0495\n",
      "    143        1.1772        1.3527  0.0458\n",
      "    144        1.2565        1.6705  0.0496\n",
      "    145        1.5303        1.2719  0.0553\n",
      "    146        1.1030        1.0765  0.0512\n",
      "    147        \u001b[36m1.0241\u001b[0m        \u001b[32m0.9569\u001b[0m  0.0500\n",
      "    148        \u001b[36m0.9551\u001b[0m        0.9836  0.0496\n",
      "    149        \u001b[36m0.9487\u001b[0m        0.9608  0.0492\n",
      "    150        1.0864        1.4830  0.0443\n",
      "    151        1.2518        1.1070  0.0495\n",
      "    152        1.0889        1.0061  0.0449\n",
      "    153        \u001b[36m0.9230\u001b[0m        \u001b[32m0.8889\u001b[0m  0.0493\n",
      "    154        \u001b[36m0.8906\u001b[0m        \u001b[32m0.8605\u001b[0m  0.0486\n",
      "    155        \u001b[36m0.8573\u001b[0m        0.8745  0.0440\n",
      "    156        \u001b[36m0.8468\u001b[0m        \u001b[32m0.8396\u001b[0m  0.0422\n",
      "    157        \u001b[36m0.8127\u001b[0m        \u001b[32m0.8356\u001b[0m  0.0432\n",
      "    158        \u001b[36m0.7912\u001b[0m        \u001b[32m0.7914\u001b[0m  0.0491\n",
      "    159        \u001b[36m0.7816\u001b[0m        \u001b[32m0.7893\u001b[0m  0.0565\n",
      "    160        \u001b[36m0.7784\u001b[0m        0.8524  0.0522\n",
      "    161        1.2866        2.1922  0.0436\n",
      "    162        1.7155        1.4992  0.0503\n",
      "    163        1.6106        1.8438  0.0498\n",
      "    164        1.1647        1.1238  0.0459\n",
      "    165        0.8861        0.9673  0.0444\n",
      "    166        0.9326        1.3455  0.0509\n",
      "    167        1.8809        2.3597  0.0515\n",
      "    168        2.4886        2.0344  0.0523\n",
      "    169        1.3805        1.1365  0.0509\n",
      "    170        0.9132        0.8951  0.0514\n",
      "    171        0.7874        0.9199  0.0507\n",
      "    172        1.5203        0.9226  0.0512\n",
      "    173        1.1107        1.0786  0.0509\n",
      "    174        0.7950        \u001b[32m0.6911\u001b[0m  0.0454\n",
      "    175        \u001b[36m0.6740\u001b[0m        \u001b[32m0.6249\u001b[0m  0.0518\n",
      "    176        \u001b[36m0.6336\u001b[0m        0.6389  0.0449\n",
      "    177        \u001b[36m0.6198\u001b[0m        0.6313  0.0428\n",
      "    178        \u001b[36m0.6069\u001b[0m        \u001b[32m0.6029\u001b[0m  0.0455\n",
      "    179        \u001b[36m0.5911\u001b[0m        0.6279  0.0443\n",
      "    180        0.6238        0.6630  0.0431\n",
      "    181        0.7838        0.9748  0.0444\n",
      "    182        1.0933        1.1247  0.0425\n",
      "    183        0.8591        0.8609  0.0434\n",
      "    184        0.7054        0.6954  0.0509\n",
      "    185        0.9921        1.3556  0.0499\n",
      "    186        1.3693        1.0883  0.0424\n",
      "    187        0.9542        \u001b[32m0.5761\u001b[0m  0.0508\n",
      "    188        0.6686        \u001b[32m0.5574\u001b[0m  0.0502\n",
      "    189        0.5994        0.7994  0.0442\n",
      "    190        1.4744        1.7675  0.0445\n",
      "    191        1.4762        1.5739  0.0463\n",
      "    192        1.3545        0.8603  0.0444\n",
      "    193        0.7630        0.8242  0.0517\n",
      "    194        0.7461        0.6023  0.0514\n",
      "    195        0.7236        0.7888  0.0512\n",
      "    196        0.7752        0.7125  0.0512\n",
      "    197        1.2163        0.7844  0.0435\n",
      "    198        0.7708        0.7578  0.0515\n",
      "    199        0.6250        0.7484  0.0444\n",
      "    200        0.7455        1.3854  0.0513\n",
      "\n",
      "*** Training quantile prediction model ***\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m28.4350\u001b[0m        \u001b[32m0.3732\u001b[0m  1.0640\n",
      "      2        \u001b[36m0.3771\u001b[0m        \u001b[32m0.3681\u001b[0m  1.0910\n",
      "      3        \u001b[36m0.3528\u001b[0m        0.3787  1.0955\n",
      "      4        \u001b[36m0.3500\u001b[0m        \u001b[32m0.3355\u001b[0m  1.0855\n",
      "      5        \u001b[36m0.3481\u001b[0m        0.3448  1.0950\n",
      "      6        0.3586        0.3564  1.0698\n",
      "      7        \u001b[36m0.3347\u001b[0m        0.3604  1.0944\n",
      "      8        0.3421        0.3660  1.0852\n",
      "      9        0.3437        0.3424  1.0815\n",
      "     10        0.3448        0.3456  1.0786\n",
      "     11        0.3477        \u001b[32m0.3250\u001b[0m  1.0843\n",
      "     12        0.3505        0.3376  1.0857\n",
      "     13        0.3639        0.3340  1.0748\n",
      "     14        0.3451        0.3305  1.0715\n",
      "     15        0.3586        0.3452  1.0921\n",
      "     16        0.3589        0.3560  1.0893\n",
      "     17        0.3394        0.3551  1.0767\n",
      "     18        0.3522        0.3427  1.0930\n",
      "     19        0.3479        0.3655  1.0896\n",
      "     20        0.3519        0.3673  1.0838\n",
      "     21        0.3609        0.3607  1.0983\n",
      "     22        0.3573        0.3543  1.0712\n",
      "     23        0.3586        0.3605  1.0956\n",
      "     24        0.3611        0.3583  1.1665\n",
      "     25        0.3577        0.3378  1.3532\n"
     ]
    }
   ],
   "source": [
    "trr.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4945774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02938868],\n",
       "       [-0.02938868],\n",
       "       [-0.02938868],\n",
       "       ...,\n",
       "       [-0.02938868],\n",
       "       [-0.02938868],\n",
       "       [-0.02938868]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trr.predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b249fa",
   "metadata": {},
   "source": [
    "# TODO: Something is obviously going wrong, but at least I'm getting through it all."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
