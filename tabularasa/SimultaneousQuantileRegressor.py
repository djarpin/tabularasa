import torch
from sklearn.base import RegressorMixin
from skorch import NeuralNet
from skorch.dataset import unpack_data
from .MixedMonotonicNet import MixedMonotonicNet
from tabularasa.gumnn.MultidimensionnalMonotonicNN import SlowDMonotonicNN


class SimultaneousQuantileMixedMonotonicNet(MixedMonotonicNet):

    def __init__(self,
                 non_monotonic_net,
                 dim_non_monotonic,
                 dim_monotonic,
                 layers=[512, 512, 64],
                 dim_out=1,
                 integration_steps=50,
                 device='cpu'):
        super().__init__(non_monotonic_net,
                         dim_non_monotonic,
                         dim_monotonic,
                         layers,
                         dim_out,
                         integration_steps,
                         device)
        self.non_monotonic_net = non_monotonic_net
        self.umnn = SlowDMonotonicNN(dim_monotonic,
                                     dim_non_monotonic + 1,
                                     layers,
                                     dim_out,
                                     integration_steps,
                                     device)

    def forward(self, X_monotonic, X_non_monotonic, qs):
        h = self.non_monotonic_net(X_non_monotonic)
        h = torch.cat([h, qs], 1)
        return self.umnn(X_monotonic, h)


class SimultaneousQuantileRegressor(NeuralNet, RegressorMixin):

    def __init__(self, module, *args, criterion, **kwargs):
        super(SimultaneousQuantileRegressor, self).__init__(module, *args, criterion=criterion, **kwargs)

    def get_loss(self, y_pred, y_true, X, *args, **kwargs):
        diff = y_pred - y_true
        threshold = (diff.ge(0).float() - X['qs']).detach()
        return (threshold * diff).mean()

    def train_step_single(self, batch, **fit_params):
        """Compute y_pred, loss value, and update net's gradients.
        The module is set to be in train mode (e.g. dropout is
        applied).
        Parameters
        ----------
        batch
          A single batch returned by the data loader.
        **fit_params : dict
          Additional parameters passed to the ``forward`` method of
          the module and to the ``self.train_split`` call.
        Returns
        -------
        step : dict
          A dictionary ``{'loss': loss, 'y_pred': y_pred}``, where the
          float ``loss`` is the result of the loss function and
          ``y_pred`` the prediction generated by the PyTorch module.
        """
        self._set_training(True)
        Xi, yi = unpack_data(batch)
        Xi['qs'] = torch.rand(yi.size(0), 1)
        y_pred = self.infer(Xi, **fit_params)
        loss = self.get_loss(y_pred, yi, X=Xi, training=True)
        loss.backward()
        return {
            'loss': loss,
            'y_pred': y_pred,
        }
