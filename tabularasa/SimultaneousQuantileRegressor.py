from sklearn.base import RegressorMixin
from skorch import NeuralNet
from MixedNet import MixedNet


class SQRNet(MixedNet):

    def __init__(self,
                 non_monotonic_net,
                 dim_non_monotonic,
                 dim_monotonic,
                 layers=[512, 512, 64],
                 dim_out=1,
                 integration_steps=50,
                 device='cpu'):
        super().__init__()
        self.non_monotonic_net = non_monotonic_net
        self.umnn = SlowDMonotonicNN(dim_monotonic,
                                     dim_non_monotonic + 1,
                                     layers,
                                     dim_out,
                                     integration_steps,
                                     device)


class SimultaneousQuantileRegressor(NeuralNet, RegressorMixin):

    def __init__(self, module, *args, **kwargs):
        super(SimultaneousQuantileRegressor, self).__init__(module, *args, **kwargs)

    # Have to add a dimension to the first layer in the input network
    # Maybe I should do class inheritance on MixedNet() (see above)?
    # There appears to be an example of changing it here otherwise
    # which I could do in the __init__ of this class
    # https://pytorch.org/docs/stable/generated/torch.full.html

    def get_loss(self, y_pred, y_true, X, qs=None, *args, **kwargs):
        diff = y_pred - y_true
        threshold = (diff.ge(0).float() - qs).detach()
        return (threshold * diff).mean()

    def train_step_single(self, batch, **fit_params):
        """Compute y_pred, loss value, and update net's gradients.
        The module is set to be in train mode (e.g. dropout is
        applied).
        Parameters
        ----------
        batch
          A single batch returned by the data loader.
        **fit_params : dict
          Additional parameters passed to the ``forward`` method of
          the module and to the ``self.train_split`` call.
        Returns
        -------
        step : dict
          A dictionary ``{'loss': loss, 'y_pred': y_pred}``, where the
          float ``loss`` is the result of the loss function and
          ``y_pred`` the prediction generated by the PyTorch module.
        """
        self._set_training(True)
        Xi, yi = unpack_data(batch)
        qs = torch.rand(Xi.size(0), 1)
        Xi = torch.cat([Xi, qs], 1)
        y_pred = self.infer(Xi, **fit_params)
        loss = self.get_loss(y_pred, yi, X=Xi, training=True, qs=qs)
        loss.backward()
        return {
            'loss': loss,
            'y_pred': y_pred,
        }
